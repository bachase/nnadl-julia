{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(\"nnadl-julia/neuralnet.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = NeuralNet.Network([2;3;2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Network([2,3,2],[\n",
        "3x2 Array{Float64,2}:\n",
        " 0.207276   1.52676  \n",
        " 0.849024  -0.159867 \n",
        " 1.46481    0.0767592,\n",
        "\n",
        "2x3 Array{Float64,2}:\n",
        " -0.714715   0.815781   0.204955\n",
        "  0.871498  -0.512168  -1.30869 ],[[-0.14313945510741935,1.9696980675544669,0.7109137232695631],[-1.0534671729715952,0.08020436033870665]])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "length(n.layers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Verify backward prop\n",
      "Manually verify cost derivatives "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_input = [1 1; 2 2]\n",
      "test_output = [1 1;2 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "2x2 Array{Int64,2}:\n",
        " 1  1\n",
        " 2  2"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Test Bias"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "delta = 1e-5\n",
      "function test_bias(network, layer, neuron, delta = 1e-5)\n",
      "    nb_upper = deepcopy(network)\n",
      "    nb_lower = deepcopy(network)\n",
      "    nb_upper.bias[layer][neuron] += delta\n",
      "    nb_lower.bias[layer][neuron] -= delta\n",
      "    cost_upper = NeuralNet.cost(nb_upper, test_input, test_output)\n",
      "    cost_lower = NeuralNet.cost(nb_lower, test_input, test_output)\n",
      "    (cost_upper - cost_lower)/(2*delta)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "test_bias (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function test_weights(network, layer, neuronA,neuronB, delta = 1e-5)\n",
      "    nw_upper = deepcopy(network)\n",
      "    nw_lower = deepcopy(network)\n",
      "    nw_upper.weights[layer][neuronA,neuronB] += delta\n",
      "    nw_lower.weights[layer][neuronA,neuronB] -= delta\n",
      "    costw_upper = NeuralNet.cost(nw_upper, test_input, test_output)\n",
      "    costw_lower = NeuralNet.cost(nw_lower, test_input, test_output)\n",
      "    (costw_upper - costw_lower)/(2*delta)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "test_weights (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testDerive = NeuralNet.backpropagate(n,test_input,test_output)\n",
      "for (layer, numNeurons) in enumerate(n.layers[2:end])\n",
      "    @printf(\"Layer %d\\n\",layer)\n",
      "    for neuron in 1:numNeurons\n",
      "        @printf(\"Bias Neuron %d\\n\", neuron)\n",
      "        a = test_bias(n, layer, neuron)\n",
      "        b = testDerive[1][layer][neuron]\n",
      "        @Test.test_approx_eq_eps a b 1e-6\n",
      "    end\n",
      "    @printf(\"Weights\")\n",
      "    for neuronA in 1:n.layers[layer], neuronB in 1:n.layers[layer+1]\n",
      "        a = test_weights(n, layer, neuronB, neuronA)\n",
      "        b = testDerive[2][layer][neuronB,neuronA]\n",
      "        @Test.test_approx_eq_eps a b 1e-6\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Layer 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Bias Neuron 1\n",
        "Bias Neuron "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "Bias Neuron 3\n",
        "WeightsLayer 2\n",
        "Bias Neuron 1\n",
        "Bias Neuron 2\n",
        "Weights"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}